<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <title>DTI Methodology - Distro Transparency Index</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
       <header>
          <h1>
    <img src="images/dtilogo48.png" alt="DTI Logo" width="48" height="48" style="vertical-align: middle; margin-right: 10px;">
    Distro Transparency Index (DTI)
</h1>
   <nav>
    <ul>
         <li><a href="../index.html">Home</a></li>
                <li><a href="../methodology.html">Methodology</a></li>
                <li><a href="../about.html">About</a></li>
                <li><a href="../constitution.html">Constitution</a></li>
                 <li><a href="../DTI 2025 Roadmap.html">2025 Roadmap</a></li>
                <li><a href="../board.html">Be part of the team!</a></li>
    </ul>
</nav>
    </header>
    <main>

<div class="container-lg px-3 my-5 markdown-body">
        <h1><a href="https://distrotransparencyindex.github.io/distro-transparency-index/">Distro Transparency Index</a></h1>
        <h1 id="methodology">Methodology</h1>

        <h4 id="index">Index</h4>
        <ul>
            <li><a href="#evaluation-criteria">Evaluation Criteria</a></li>
            <li><a href="#point-assignment">Evaluation Criteria and Point Assignment</a></li>
            <li><a href="#responsiveness">Responsiveness to Transparency Requests</a></li>
            <li><a href="#scientific-references">Scientific References and Similar Models</a></li>
        </ul>

        

        
        <h2>DTI Methodology</h2>
        <section>
            <h3>Overview</h3>
            <p>The Distro Transparency Index (DTI) is a comprehensive evaluation system designed to assess the transparency of Linux distributions across various key aspects of their operations and governance.</p>
        </section>
        <section>
           <h2 id="evaluation-criteria">Evaluation Criteria</h2>
            <ol>
                <li>
                    <h4>Governance Transparency</h4>
                    <p>This criterion evaluates the availability and detail of governance documents, the openness of decision-making processes, and the level of community involvement in governance.</p>
                </li>
                <li>
                    <h4>Economic Transparency</h4>
                    <p>We assess the publication and accessibility of financial reports, budgets, and funding sources. This includes the regularity of financial disclosures and the ease of access to this information.</p>
                </li>
                <li>
                    <h4>Code Accessibility and Development</h4>
                    <p>This criterion examines the accessibility of source code, the transparency of code review processes, and the level of community participation in the development process.</p>
                </li>
            </ol>
        </section>
        <section>
            <h3>Scoring System</h3>
            <p>Each distribution is scored on a scale of 0-100, based on their performance across the evaluation criteria. The scoring is broken down as follows:</p>
            <ul>
                <li>Governance Transparency: 33.33%</li>
                <li>Economic Transparency: 33.33%</li>
                <li>Code Accessibility and Development: 33.33%</li>
            </ul>
            <p>Within each category, specific metrics are evaluated and contribute to the overall score for that category.</p>
        </section>
        <section>
            <h3>Data Collection</h3>
            <p>Our data is collected through a rigorous process that includes:</p>
            <ul>
                <li>Thorough examination of public documents and official websites</li>
                <li>Analysis of community forums and discussion platforms</li>
                <li>Review of code repositories and development processes</li>
                <li>Direct communication with distribution maintainers when necessary</li>
            </ul>
            <p>We strive to ensure all data is current and accurately reflects the most recent state of each distribution.</p>
        </section>
        <section>
            <h3>Updating and Revision</h3>
            <p>The DTI is regularly updated to ensure its relevance and accuracy. We conduct full reviews of all distributions annually, with interim updates as significant changes occur.</p>
        </section>
        <section>
            <h3>Feedback and Contributions</h3>
            <p>We welcome feedback from the community and the distributions themselves. If you have information that could improve our assessment or notice any inaccuracies, please contact us.</p>
       <h2 id="point-assignment">Evaluation Criteria and Point Assignment</h2>
            <ol>
                <li>
                    <h4>Governance Transparency (3 points)</h4>
                    <p>Availability of governance documents: Yes (1 point), No (0 points)</p>
                    <p>Detail of governance documents: Detailed (2 points), Partial (1 point), Minimal (0 points)</p>
                </li>
                <li>
                    <h4>Decision Making Transparency (3 points)</h4>
                    <p>Documented decision-making process: Yes (1 point), No (0 points)</p>
                    <p>Accessibility of meeting minutes: Public (2 points), Partial (1 point), Not available (0 points)</p>
                </li>
                <li>
                    <h4>Economic Transparency (4 points)</h4>
                    <p>Publication of financial statements: Annual (2 points), Partial (1 point), Not published (0 points)</p>
                    <p>Detail of financial statements: Detailed (2 points), Partial (1 point), Minimal (0 points)</p>
                </li>
                <li>
                    <h4>Economic Accessibility (4 points)</h4>
                    <p>Access to financial reports: Free (2 points), Restricted (1 point), Not available (0 points)</p>
                    <p>Ease of access: Easy (2 points), Moderate (1 point), Difficult (0 points)</p>
                </li>
                <li>
                    <h4>Source Code Accessibility (4 points)</h4>
                    <p>Availability of source code: Public (2 points), Partial (1 point), Private (0 points)</p>
                    <p>Ease of access to source code: Easy (2 points), Moderate (1 point), Difficult (0 points)</p>
                </li>
                <li>
                    <h4>Public Roadmap / Development Transparency (3 or 5 points)</h4>
                    <p>For non-rolling releases:</p>
                    <p>Public roadmap: Yes (1 point), No (0 points)</p>
                    <p>Detail of roadmap: Detailed (2 points), Partial (1 point), Minimal (0 points)</p>
                    <p>For rolling releases:</p>
                    <p>Transparency of continuous development process: High (3 points), Medium (2 points), Low (1 point)</p>
                    <p>Accessibility to information on upcoming updates: Easy (2 points), Moderate (1 point), Difficult (0 points)</p>
                </li>
                <li>
                    <h4>Transparency in Code Review Processes (3 points)</h4>
                    <p>Documentation of review processes: Yes (1 point), No (0 points)</p>
                    <p>Transparency of review processes: High (2 points), Moderate (1 point), Low (0 points)</p>
                </li>
                <li>
                    <h4>Community Participation in Development (4 points)</h4>
                    <p>Number of active contributors: High (2 points), Moderate (1 point), Low (0 points)</p>
                    <p>Accessibility to development processes: Easy (2 points), Moderate (1 point), Difficult (0 points)</p>
                </li>
                <li>
                    <h4>Impact of Governance Structure on Transparency (6 points)</h4>
                    <p>Centralization of decision-making power: Decentralized (2 points), Partially centralized (1 point), Highly centralized (0 points)</p>
                    <p>Control and balance mechanisms: Strong (2 points), Moderate (1 point), Weak (0 points)</p>
                    <p>Influence of commercial entities on governance: Minimal (2 points), Moderate (1 point), Significant (0 points)</p>
                </li>
            </ol>
        </section>
        <section>
            <h3>Rolling vs. Non-Rolling Releases</h3>
            <p>We distinguish between rolling release and non-rolling release distributions in our evaluation:</p>
            <ul>
                <li><strong>Rolling Release:</strong> These distributions continuously update all system components. For these, we evaluate the transparency of the continuous development process and the accessibility of information on upcoming updates.</li>
                <li><strong>Non-Rolling Release:</strong> These distributions have scheduled, discrete releases. For these, we evaluate the availability and detail of a public roadmap.</li>
            </ul>
            <p>This distinction ensures that we fairly evaluate distributions based on their release model, recognizing that transparency manifests differently in these two approaches.</p>
        </section>
        <section>
            <h3>Centralized Governance Penalization</h3>
            <p>Our methodology penalizes centralized governance structures for several reasons:</p>
            <ul>
                <li>Centralized structures often lead to less community involvement in decision-making processes.</li>
                <li>They can result in less transparent operations, as decisions may be made by a small group without public input.</li>
                <li>Decentralized structures typically align better with open-source principles of collaboration and shared responsibility.</li>
                <li>Community-driven projects often demonstrate higher levels of transparency and accountability.</li>
            </ul>
            <p>However, we recognize that some degree of centralization can be beneficial for efficient decision-making. Our scoring system aims to balance these considerations, rewarding distributions that maintain transparency and community involvement even with more centralized structures.</p>
        </section>
 <h2 id="responsiveness">Responsiveness to Transparency Requests</h2>

    <p>To assess the active commitment of distributions to transparency, we have introduced a category that measures their responsiveness to direct requests for information.</p>

    <h3>Evaluation Criteria:</h3>

    <ol>
        <li>Response to request:
            <ul>
                <li>Complete and timely response (within 2 weeks): +15 points</li>
                <li>Partial or delayed response (within 1 month): +10 points</li>
                <li>Minimal or very delayed response (beyond 1 month): +5 points</li>
                <li>No response: -15 points</li>
            </ul>
        </li>
        <li>Quality of information provided:
            <ul>
                <li>Complete and detailed information: +10 points</li>
                <li>Partial but useful information: +5 points</li>
                <li>Minimal or irrelevant information: +0 points</li>
            </ul>
        </li>
    </ol>

    <p>This category allows for adding up to 25 points to the total score or subtracting 15 points in case of no response, reflecting the importance we attribute to the openness and active collaboration of distributions in providing transparent information.</p>

    <h3>80-Point Limit for Bonus Points</h3>

    <p>To maintain fairness and prevent distributions with initially lower scores from unduly surpassing those that were already highly transparent, we've implemented an 80-point limit for distributions receiving bonus points from responsiveness:</p>

    <ul>
        <li>Distributions that score 80 points or higher in their initial evaluation are not sent additional information requests, as they have already demonstrated a high level of transparency.</li>
        <li>Distributions receiving bonus points from responsiveness cannot exceed a final score of 80 points, regardless of their initial score plus bonus.</li>
        <li>This limit ensures that responsive but initially less transparent distributions can significantly improve their standing without overtaking the most transparent projects.</li>
    </ul>

    <h4>Score Calculation and Presentation</h4>

    <p>The total score of a distribution is calculated by summing the points obtained in all categories, including the Responsiveness to Transparency Requests category, subject to the 80-point limit for bonus recipients.</p>

    <ul>
        <li>Maximum possible score without bonus: 100 points</li>
        <li>Maximum possible score with bonus: 80 points</li>
    </ul>

    <h3>Score Presentation</h3>

    <p>In our rankings and individual distribution pages, we display the scores as follows:</p>

    <ul>
        <li>For distributions without bonus:<br>
            <code>DistroName 👥🤝🏦 82.35/100 🏛️🟢 💰🟢 💻🟢</code></li>
        <li>For distributions with bonus:<br>
            <code>*DistroName 👥🤝🏦 80(66.76)/100 🏛️🟢 💰🟡 💻🟢 ✉️🟢+25</code></li>
    </ul>

    <p>Where:</p>
    <ul>
        <li>The asterisk (*) indicates the distribution received a bonus.</li>
        <li>80 is the capped final score.</li>
        <li>(66.76) is the original score before the bonus.</li>
        <li>✉️🟢+25 indicates a full positive response to our transparency request.</li>
    </ul>

    <p>This presentation method ensures transparency in our scoring process, clearly showing both the original and bonus-adjusted scores while maintaining the integrity of our evaluation system.</p>
        </section>
<section id="scientific-references">
    <h2 id="scientific-references">Scientific References and Similar Models</h2>
    <p>The methodology used in the Distro Transparency Index (DTI) is inspired by and draws upon various scientific models and frameworks for evaluating transparency, governance, and maturity in open-source projects and organizations. While our approach is tailored specifically to Linux distributions, it builds upon established research in the field. Some relevant scientific references and similar models include:</p>
    
    <ol>
        <li>
            <strong>Open Source Maturity Model (OSMM):</strong>
            <p>Golden, Bernard. "Succeeding with Open Source." Addison-Wesley Professional, 2004.</p>
            <p>The OSMM provides a framework for evaluating the maturity of open-source projects, including aspects of governance and transparency.</p>
        </li>
        
        <li>
            <strong>Qualification and Selection of Open Source Software (QSOS):</strong>
            <p>Deprez, Jean-Christophe, and Simon Alexandre. "Comparing assessment methodologies for free/open source software: OpenBRR and QSOS." International Conference on Product Focused Software Process Improvement. Springer, Berlin, Heidelberg, 2008.</p>
            <p>QSOS offers a comprehensive framework for assessing open-source projects.</p>
        </li>
        
        <li>
            <strong>Organizational Transparency Model:</strong>
            <p>Schnackenberg, Andrew K., and Edward C. Tomlinson. "Organizational transparency: A new perspective on managing trust in organization-stakeholder relationships." Journal of Management 42.7 (2016): 1784-1810.</p>
            <p>This article provides a framework for evaluating transparency in organizations, which we've adapted for open-source projects.</p>
        </li>
        
        <li>
            <strong>Capability Maturity Model Integration (CMMI):</strong>
            <p>Team, CMMI Product. "CMMI for development, version 1.2." (2006).</p>
            <p>While not specific to open source, CMMI assesses the maturity of software development processes, which informed our evaluation criteria.</p>
        </li>
        
        <li>
            <strong>Open Source Governance Evaluation Model:</strong>
            <p>de Laat, Paul B. "Governance of open source software: state of the art." Journal of Management & Governance 11.2 (2007): 165-177.</p>
            <p>This article discusses various aspects of governance in open-source projects, which influenced our governance evaluation criteria.</p>
        </li>
        
        <li>
            <strong>Transparency Evaluation Framework in Open Source Projects:</strong>
            <p>Shaikh, Maha, and Tony Cornford. "Version management tools: CVS to BK in the Linux kernel." 3rd Workshop on Open Source Software Engineering. 2003.</p>
            <p>This paper discusses aspects of transparency in Linux kernel development, which informed our approach to evaluating development transparency.</p>
        </li>
    </ol>
    
    <p>While these models and frameworks provided inspiration and a scientific basis for our methodology, the Distro Transparency Index has been specifically tailored to address the unique challenges and characteristics of the Linux distribution ecosystem. Our approach synthesizes elements from these established models while introducing new criteria relevant to distribution-specific aspects of transparency and governance.</p>
</section>
        
    </main>
    <footer>
        <p>&copy; 2023 Distro Transparency Index</p>
    </footer>
</body>
</html>
        
        </section>
    </main>
    <footer>
        <p>&copy; 2023 Distro Transparency Index</p>
    </footer>
</body>
</html>
